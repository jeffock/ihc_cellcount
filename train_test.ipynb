{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import random\n",
    "from typing import Optional\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "\n",
    "import os\n",
    "from typing import Union, Optional, List\n",
    "\n",
    "import click\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from glob import glob\n",
    "from typing import List, Tuple\n",
    "\n",
    "import click\n",
    "import h5py\n",
    "import wget\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5Dataset(Dataset):\n",
    "    \"\"\"PyTorch dataset for HDF5 files generated with `get_data.py`.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset_path: str,\n",
    "                 horizontal_flip: float=0.0,\n",
    "                 vertical_flip: float=0.0):\n",
    "        \"\"\"\n",
    "        Initialize flips probabilities and pointers to a HDF5 file.\n",
    "\n",
    "        Args:\n",
    "            dataset_path: a path to a HDF5 file\n",
    "            horizontal_flip: the probability of applying horizontal flip\n",
    "            vertical_flip: the probability of applying vertical flip\n",
    "        \"\"\"\n",
    "        super(H5Dataset, self).__init__()\n",
    "        self.h5 = h5py.File(dataset_path, 'r')\n",
    "        self.images = self.h5['images']\n",
    "        self.labels = self.h5['labels']\n",
    "        self.horizontal_flip = horizontal_flip\n",
    "        self.vertical_flip = vertical_flip\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return no. of samples in HDF5 file.\"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"Return next sample (randomly flipped).\"\"\"\n",
    "        # if both flips probabilities are zero return an image and a label\n",
    "        if not (self.horizontal_flip or self.vertical_flip):\n",
    "            return self.images[index], self.labels[index]\n",
    "\n",
    "        # axis = 1 (vertical flip), axis = 2 (horizontal flip)\n",
    "        axis_to_flip = []\n",
    "\n",
    "        if random() < self.vertical_flip:\n",
    "            axis_to_flip.append(1)\n",
    "\n",
    "        if random() < self.horizontal_flip:\n",
    "            axis_to_flip.append(2)\n",
    "\n",
    "        return (np.flip(self.images[index], axis=axis_to_flip).copy(),\n",
    "                np.flip(self.labels[index], axis=axis_to_flip).copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loader():\n",
    "    \"\"\"Test HDF5 dataloader with flips on and off.\"\"\"\n",
    "    run_batch(flip=False)\n",
    "    run_batch(flip=True)\n",
    "\n",
    "\n",
    "def run_batch(flip):\n",
    "    \"\"\"Sanity check for HDF5 dataloader checks for shapes and empty arrays.\"\"\"\n",
    "    # datasets to test loader on\n",
    "    datasets = {\n",
    "        'cell': (3, 256, 256),\n",
    "        'mall': (3, 480, 640),\n",
    "        'ucsd': (1, 160, 240)\n",
    "    }\n",
    "\n",
    "    # for each dataset check both training and validation HDF5\n",
    "    # for each one check if shapes are right and arrays are not empty\n",
    "    for dataset, size in datasets.items():\n",
    "        for h5 in ('train.h5', 'valid.h5'):\n",
    "            # create a loader in \"all flips\" or \"no flips\" mode\n",
    "            data = H5Dataset(os.path.join(dataset, h5),\n",
    "                             horizontal_flip=1.0 * flip,\n",
    "                             vertical_flip=1.0 * flip)\n",
    "            # create dataloader with few workers\n",
    "            data_loader = DataLoader(data, batch_size=4, num_workers=4)\n",
    "\n",
    "            # take one batch, check samples, and go to the next file\n",
    "            for img, label in data_loader:\n",
    "                # image batch shape (#workers, #channels, resolution)\n",
    "                assert img.shape == (4, *size)\n",
    "                # label batch shape (#workers, 1, resolution)\n",
    "                assert label.shape == (4, 1, *size[1:])\n",
    "\n",
    "                assert torch.sum(img) > 0\n",
    "                assert torch.sum(label) > 0\n",
    "\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hdf5(dataset_name: str,\n",
    "                train_size: int,\n",
    "                valid_size: int,\n",
    "                img_size: Tuple[int, int],\n",
    "                in_channels: int=3):\n",
    "    \"\"\"\n",
    "    Create empty training and validation HDF5 files with placeholders\n",
    "    for images and labels (density maps).\n",
    "\n",
    "    Note:\n",
    "    Datasets are saved in [dataset_name]/train.h5 and [dataset_name]/valid.h5.\n",
    "    Existing files will be overwritten.\n",
    "\n",
    "    Args:\n",
    "        dataset_name: used to create a folder for train.h5 and valid.h5\n",
    "        train_size: no. of training samples\n",
    "        valid_size: no. of validation samples\n",
    "        img_size: (width, height) of a single image / density map\n",
    "        in_channels: no. of channels of an input image\n",
    "\n",
    "    Returns:\n",
    "        A tuple of pointers to training and validation HDF5 files.\n",
    "    \"\"\"\n",
    "    # create output folder if it does not exist\n",
    "    os.makedirs(dataset_name, exist_ok=True)\n",
    "\n",
    "    # create HDF5 files: [dataset_name]/(train | valid).h5\n",
    "    train_h5 = h5py.File(os.path.join(dataset_name, 'train.h5'), 'w')\n",
    "    valid_h5 = h5py.File(os.path.join(dataset_name, 'valid.h5'), 'w')\n",
    "\n",
    "    # add two HDF5 datasets (images and labels) for each HDF5 file\n",
    "    for h5, size in ((train_h5, train_size), (valid_h5, valid_size)):\n",
    "        h5.create_dataset('images', (size, in_channels, *img_size))\n",
    "        h5.create_dataset('labels', (size, 1, *img_size))\n",
    "\n",
    "    return train_h5, valid_h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label(label_info: np.array, image_shape: List[int]):\n",
    "    \"\"\"\n",
    "    Generate a density map based on objects positions.\n",
    "\n",
    "    Args:\n",
    "        label_info: (x, y) objects positions\n",
    "        image_shape: (width, height) of a density map to be generated\n",
    "\n",
    "    Returns:\n",
    "        A density map.\n",
    "    \"\"\"\n",
    "    # create an empty density map\n",
    "    label = np.zeros(image_shape, dtype=np.float32)\n",
    "\n",
    "    # loop over objects positions and marked them with 100 on a label\n",
    "    # note: *_ because some datasets contain more info except x, y coordinates\n",
    "    for x, y, *_ in label_info:\n",
    "        if y < image_shape[0] and x < image_shape[1]:\n",
    "            label[int(y)][int(x)] = 100\n",
    "\n",
    "    # apply a convolution with a Gaussian kernel\n",
    "    label = gaussian_filter(label, sigma=(1, 1), order=0)\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nuclei_data():\n",
    "    \"\"\"Generate HDF5 files for fluorescent cell dataset.\"\"\"\n",
    "    # download and extract dataset\n",
    "    location='Data_JPEG'\n",
    "\n",
    "\n",
    "    # create training and validation HDF5 files\n",
    "    train_h5, valid_h5 = create_hdf5('nuc',\n",
    "                                     train_size=150,\n",
    "                                     valid_size=50,\n",
    "                                     img_size=(256, 256),\n",
    "                                     in_channels=3)\n",
    "\n",
    "    # get the list of all samples\n",
    "    # dataset name convention: XXXcell.png (image) XXXdots.png (label)\n",
    "    image_list = glob(os.path.join('cells', '*cell.*'))\n",
    "    image_list.sort()\n",
    "\n",
    "    def fill_h5(h5, images):\n",
    "        \"\"\"\n",
    "        Save images and labels in given HDF5 file.\n",
    "\n",
    "        Args:\n",
    "            h5: HDF5 file\n",
    "            images: the list of images paths\n",
    "        \"\"\"\n",
    "        for i, img_path in enumerate(images):\n",
    "            # get label path\n",
    "            label_path = img_path.replace('cell.png', 'dots.png')\n",
    "            # get an image as numpy array\n",
    "            image = np.array(Image.open(img_path), dtype=np.float32) / 255\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "\n",
    "            # convert a label image into a density map: dataset provides labels\n",
    "            # in the form on an image with red dots placed in objects position\n",
    "\n",
    "            # load an RGB image\n",
    "            label = np.array(Image.open(label_path))\n",
    "            # make a one-channel label array with 100 in red dots positions\n",
    "            label = 100.0 * (label[:, :, 0] > 0)\n",
    "            # generate a density map by applying a Gaussian filter\n",
    "            label = gaussian_filter(label, sigma=(1, 1), order=0)\n",
    "\n",
    "            # save data to HDF5 file\n",
    "            h5['images'][i] = image\n",
    "            h5['labels'][i, 0] = label\n",
    "\n",
    "    # use first 150 samples for training and the last 50 for validation\n",
    "    fill_h5(train_h5, image_list[:150])\n",
    "    fill_h5(valid_h5, image_list[150:])\n",
    "\n",
    "    # close HDF5 files\n",
    "    train_h5.close()\n",
    "    valid_h5.close()\n",
    "\n",
    "    # cleanup\n",
    "    shutil.rmtree('cells')\n",
    "\n",
    "def generate_keratin_data():\n",
    "    \"\"\"Generate HDF5 files for fluorescent cell dataset.\"\"\"\n",
    "    # download and extract dataset\n",
    "    location='Data_JPEG'\n",
    "    # create training and validation HDF5 files\n",
    "    train_h5, valid_h5 = create_hdf5('krt',\n",
    "                                     train_size=150,\n",
    "                                     valid_size=50,\n",
    "                                     img_size=(256, 256),\n",
    "                                     in_channels=3)\n",
    "\n",
    "    # get the list of all samples\n",
    "    # dataset name convention: XXXcell.png (image) XXXdots.png (label)\n",
    "    image_list = glob(os.path.join('cells', '*cell.*'))\n",
    "    image_list.sort()\n",
    "\n",
    "    def fill_h5(h5, images):\n",
    "        \"\"\"\n",
    "        Save images and labels in given HDF5 file.\n",
    "\n",
    "        Args:\n",
    "            h5: HDF5 file\n",
    "            images: the list of images paths\n",
    "        \"\"\"\n",
    "        for i, img_path in enumerate(images):\n",
    "            # get label path\n",
    "            label_path = img_path.replace('cell.png', 'dots.png')\n",
    "            # get an image as numpy array\n",
    "            image = np.array(Image.open(img_path), dtype=np.float32) / 255\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "\n",
    "            # convert a label image into a density map: dataset provides labels\n",
    "            # in the form on an image with red dots placed in objects position\n",
    "\n",
    "            # load an RGB image\n",
    "            label = np.array(Image.open(label_path))\n",
    "            # make a one-channel label array with 100 in red dots positions\n",
    "            label = 100.0 * (label[:, :, 0] > 0)\n",
    "            # generate a density map by applying a Gaussian filter\n",
    "            label = gaussian_filter(label, sigma=(1, 1), order=0)\n",
    "\n",
    "            # save data to HDF5 file\n",
    "            h5['images'][i] = image\n",
    "            h5['labels'][i, 0] = label\n",
    "\n",
    "    # use first 150 samples for training and the last 50 for validation\n",
    "    fill_h5(train_h5, image_list[:150])\n",
    "    fill_h5(valid_h5, image_list[150:])\n",
    "\n",
    "    # close HDF5 files\n",
    "    train_h5.close()\n",
    "    valid_h5.close()\n",
    "\n",
    "    # cleanup\n",
    "    shutil.rmtree('cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@click.command()\n",
    "@click.option('--dataset',\n",
    "              type=click.Choice(['nuclei', 'cytokeratin']),\n",
    "              required=True)\n",
    "def get_data(dataset: str):\n",
    "    \"\"\"\n",
    "    Get chosen dataset and generate HDF5 files with training\n",
    "    and validation samples.\n",
    "    \"\"\"\n",
    "    # dictionary-based switch statement\n",
    "    {\n",
    "        'cell': generate_nuclei_data,\n",
    "        'mall': generate_keratin_data,\n",
    "    }[dataset]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(channels: Tuple[int, int],\n",
    "               size: Tuple[int, int],\n",
    "               stride: Tuple[int, int]=(1, 1),\n",
    "               N: int=1):\n",
    "    \"\"\"\n",
    "    Create a block with N convolutional layers with ReLU activation function.\n",
    "    The first layer is IN x OUT, and all others - OUT x OUT.\n",
    "\n",
    "    Args:\n",
    "        channels: (IN, OUT) - no. of input and output channels\n",
    "        size: kernel size (fixed for all convolution in a block)\n",
    "        stride: stride (fixed for all convolution in a block)\n",
    "        N: no. of convolutional layers\n",
    "\n",
    "    Returns:\n",
    "        A sequential container of N convolutional layers.\n",
    "    \"\"\"\n",
    "    # a single convolution + batch normalization + ReLU block\n",
    "    block = lambda in_channels: nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels,\n",
    "                  out_channels=channels[1],\n",
    "                  kernel_size=size,\n",
    "                  stride=stride,\n",
    "                  bias=False,\n",
    "                  padding=(size[0] // 2, size[1] // 2)),\n",
    "        nn.BatchNorm2d(num_features=channels[1]),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "    # create and return a sequential container of convolutional layers\n",
    "    # input size = channels[0] for first block and channels[1] for all others\n",
    "    return nn.Sequential(*[block(channels[bool(i)]) for i in range(N)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ConvCat, FCRN-A, UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvCat(nn.Module):\n",
    "    \"\"\"Convolution with upsampling + concatenate block.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 channels: Tuple[int, int],\n",
    "                 size: Tuple[int, int],\n",
    "                 stride: Tuple[int, int]=(1, 1),\n",
    "                 N: int=1):\n",
    "        \"\"\"\n",
    "        Create a sequential container with convolutional block (see conv_block)\n",
    "        with N convolutional layers and upsampling by factor 2.\n",
    "        \"\"\"\n",
    "        super(ConvCat, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            conv_block(channels, size, stride, N),\n",
    "            nn.Upsample(scale_factor=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, to_conv: torch.Tensor, to_cat: torch.Tensor):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Args:\n",
    "            to_conv: input passed to convolutional block and upsampling\n",
    "            to_cat: input concatenated with the output of a conv block\n",
    "        \"\"\"\n",
    "        return torch.cat([self.conv(to_conv), to_cat], dim=1)\n",
    "\n",
    "\n",
    "class FCRN_A(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully Convolutional Regression Network A\n",
    "\n",
    "    Ref. W. Xie et al. 'Microscopy Cell Counting with Fully Convolutional\n",
    "    Regression Networks'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, N: int=1, input_filters: int=3, **kwargs):\n",
    "        \"\"\"\n",
    "        Create FCRN-A model with:\n",
    "\n",
    "            * fixed kernel size = (3, 3)\n",
    "            * fixed max pooling kernel size = (2, 2) and upsampling factor = 2\n",
    "            * no. of filters as defined in an original model:\n",
    "              input size -> 32 -> 64 -> 128 -> 512 -> 128 -> 64 -> 1\n",
    "\n",
    "        Args:\n",
    "            N: no. of convolutional layers per block (see conv_block)\n",
    "            input_filters: no. of input channels\n",
    "        \"\"\"\n",
    "        super(FCRN_A, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # downsampling\n",
    "            conv_block(channels=(input_filters, 32), size=(3, 3), N=N),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            conv_block(channels=(32, 64), size=(3, 3), N=N),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            conv_block(channels=(64, 128), size=(3, 3), N=N),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # \"convolutional fully connected\"\n",
    "            conv_block(channels=(128, 512), size=(3, 3), N=N),\n",
    "\n",
    "            # upsampling\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            conv_block(channels=(512, 128), size=(3, 3), N=N),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            conv_block(channels=(128, 64), size=(3, 3), N=N),\n",
    "\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            conv_block(channels=(64, 1), size=(3, 3), N=N),\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        return self.model(input)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net implementation.\n",
    "\n",
    "    Ref. O. Ronneberger et al. \"U-net: Convolutional networks for biomedical\n",
    "    image segmentation.\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filters: int=64, input_filters: int=3, **kwargs):\n",
    "        \"\"\"\n",
    "        Create U-Net model with:\n",
    "\n",
    "            * fixed kernel size = (3, 3)\n",
    "            * fixed max pooling kernel size = (2, 2) and upsampling factor = 2\n",
    "            * fixed no. of convolutional layers per block = 2 (see conv_block)\n",
    "            * constant no. of filters for convolutional layers\n",
    "\n",
    "        Args:\n",
    "            filters: no. of filters for convolutional layers\n",
    "            input_filters: no. of input channels\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        # first block channels size\n",
    "        initial_filters = (input_filters, filters)\n",
    "        # channels size for downsampling\n",
    "        down_filters = (filters, filters)\n",
    "        # channels size for upsampling (input doubled because of concatenate)\n",
    "        up_filters = (2 * filters, filters)\n",
    "\n",
    "        # downsampling\n",
    "        self.block1 = conv_block(channels=initial_filters, size=(3, 3), N=2)\n",
    "        self.block2 = conv_block(channels=down_filters, size=(3, 3), N=2)\n",
    "        self.block3 = conv_block(channels=down_filters, size=(3, 3), N=2)\n",
    "\n",
    "        # upsampling\n",
    "        self.block4 = ConvCat(channels=down_filters, size=(3, 3), N=2)\n",
    "        self.block5 = ConvCat(channels=up_filters, size=(3, 3), N=2)\n",
    "        self.block6 = ConvCat(channels=up_filters, size=(3, 3), N=2)\n",
    "\n",
    "        # density prediction\n",
    "        self.block7 = conv_block(channels=up_filters, size=(3, 3), N=2)\n",
    "        self.density_pred = nn.Conv2d(in_channels=filters, out_channels=1,\n",
    "                                      kernel_size=(1, 1), bias=False)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        # use the same max pooling kernel size (2, 2) across the network\n",
    "        pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # downsampling\n",
    "        block1 = self.block1(input)\n",
    "        pool1 = pool(block1)\n",
    "        block2 = self.block2(pool1)\n",
    "        pool2 = pool(block2)\n",
    "        block3 = self.block3(pool2)\n",
    "        pool3 = pool(block3)\n",
    "\n",
    "        # upsampling\n",
    "        block4 = self.block4(pool3, block3)\n",
    "        block5 = self.block5(block4, block2)\n",
    "        block6 = self.block6(block5, block1)\n",
    "\n",
    "        # density prediction\n",
    "        block7 = self.block7(block6)\n",
    "        return self.density_pred(block7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(network: nn.Module, input_channels: int):\n",
    "    \"\"\"Generate a random image, run through network, and check output size.\"\"\"\n",
    "    sample = torch.ones((1, input_channels, 224, 224))\n",
    "    result = network(input_filters=input_channels)(sample)\n",
    "    assert result.shape == (1, 1, 224, 224)\n",
    "\n",
    "\n",
    "def test_UNet_color():\n",
    "    \"\"\"Test U-Net on RGB images.\"\"\"\n",
    "    run_network(UNet, 3)\n",
    "\n",
    "\n",
    "def test_UNet_grayscale():\n",
    "    \"\"\"Test U-Net on grayscale images.\"\"\"\n",
    "    run_network(UNet, 1)\n",
    "\n",
    "\n",
    "def test_FRCN_color():\n",
    "    \"\"\"Test FCRN-A on RGB images.\"\"\"\n",
    "    run_network(FCRN_A, 3)\n",
    "\n",
    "\n",
    "def test_FRCN_grayscale():\n",
    "    \"\"\"Test FCRN-A on grayscale images.\"\"\"\n",
    "    run_network(FCRN_A, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jeffo\\Coding\\ihc_cellcount\\train_test.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jeffo/Coding/ihc_cellcount/train_test.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m H5Dataset\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeffo/Coding/ihc_cellcount/train_test.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlooper\u001b[39;00m \u001b[39mimport\u001b[39;00m Looper\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeffo/Coding/ihc_cellcount/train_test.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m UNet, FCRN_A\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_loader'"
     ]
    }
   ],
   "source": [
    "from data_loader import H5Dataset\n",
    "from looper import Looper\n",
    "from model import UNet, FCRN_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Looper():\n",
    "    \"\"\"Looper handles epoch loops, logging, and plotting.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 network: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 loss: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 data_loader: torch.utils.data.DataLoader,\n",
    "                 dataset_size: int,\n",
    "                 plots: Optional[matplotlib.axes.Axes]=None,\n",
    "                 validation: bool=False):\n",
    "        \"\"\"\n",
    "        Initialize Looper.\n",
    "\n",
    "        Args:\n",
    "            network: already initialized model\n",
    "            device: a device model is working on\n",
    "            loss: the cost function\n",
    "            optimizer: already initialized optimizer link to network parameters\n",
    "            data_loader: already initialized data loader\n",
    "            dataset_size: no. of samples in dataset\n",
    "            plot: matplotlib axes\n",
    "            validation: flag to set train or eval mode\n",
    "\n",
    "        \"\"\"\n",
    "        self.network = network\n",
    "        self.device = device\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.loader = data_loader\n",
    "        self.size = dataset_size\n",
    "        self.validation = validation\n",
    "        self.plots = plots\n",
    "        self.running_loss = []\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run a single epoch loop.\n",
    "\n",
    "        Returns:\n",
    "            Mean absolute error.\n",
    "        \"\"\"\n",
    "        # reset current results and add next entry for running loss\n",
    "        self.true_values = []\n",
    "        self.predicted_values = []\n",
    "        self.running_loss.append(0)\n",
    "\n",
    "        # set a proper mode: train or eval\n",
    "        self.network.train(not self.validation)\n",
    "\n",
    "        for image, label in self.loader:\n",
    "            # move images and labels to given device\n",
    "            image = image.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "\n",
    "            # clear accumulated gradient if in train mode\n",
    "            if not self.validation:\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "            # get model prediction (a density map)\n",
    "            result = self.network(image)\n",
    "\n",
    "            # calculate loss and update running loss\n",
    "            loss = self.loss(result, label)\n",
    "            self.running_loss[-1] += image.shape[0] * loss.item() / self.size\n",
    "\n",
    "            # update weights if in train mode\n",
    "            if not self.validation:\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # loop over batch samples\n",
    "            for true, predicted in zip(label, result):\n",
    "                # integrate a density map to get no. of objects\n",
    "                # note: density maps were normalized to 100 * no. of objects\n",
    "                #       to make network learn better\n",
    "                true_counts = torch.sum(true).item() / 100\n",
    "                predicted_counts = torch.sum(predicted).item() / 100\n",
    "\n",
    "                # update current epoch results\n",
    "                self.true_values.append(true_counts)\n",
    "                self.predicted_values.append(predicted_counts)\n",
    "\n",
    "        # calculate errors and standard deviation\n",
    "        self.update_errors()\n",
    "\n",
    "        # update live plot\n",
    "        if self.plots is not None:\n",
    "            self.plot()\n",
    "\n",
    "        # print epoch summary\n",
    "        self.log()\n",
    "\n",
    "        return self.mean_abs_err\n",
    "\n",
    "    def update_errors(self):\n",
    "        \"\"\"\n",
    "        Calculate errors and standard deviation based on current\n",
    "        true and predicted values.\n",
    "        \"\"\"\n",
    "        self.err = [true - predicted for true, predicted in\n",
    "                    zip(self.true_values, self.predicted_values)]\n",
    "        self.abs_err = [abs(error) for error in self.err]\n",
    "        self.mean_err = sum(self.err) / self.size\n",
    "        self.mean_abs_err = sum(self.abs_err) / self.size\n",
    "        self.std = np.array(self.err).std()\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"Plot true vs predicted counts and loss.\"\"\"\n",
    "        # true vs predicted counts\n",
    "        true_line = [[0, max(self.true_values)]] * 2  # y = x\n",
    "        self.plots[0].cla()\n",
    "        self.plots[0].set_title('Train' if not self.validation else 'Valid')\n",
    "        self.plots[0].set_xlabel('True value')\n",
    "        self.plots[0].set_ylabel('Predicted value')\n",
    "        self.plots[0].plot(*true_line, 'r-')\n",
    "        self.plots[0].scatter(self.true_values, self.predicted_values)\n",
    "\n",
    "        # loss\n",
    "        epochs = np.arange(1, len(self.running_loss) + 1)\n",
    "        self.plots[1].cla()\n",
    "        self.plots[1].set_title('Train' if not self.validation else 'Valid')\n",
    "        self.plots[1].set_xlabel('Epoch')\n",
    "        self.plots[1].set_ylabel('Loss')\n",
    "        self.plots[1].plot(epochs, self.running_loss)\n",
    "\n",
    "        matplotlib.pyplot.pause(0.01)\n",
    "        matplotlib.pyplot.tight_layout()\n",
    "\n",
    "    def log(self):\n",
    "        \"\"\"Print current epoch results.\"\"\"\n",
    "        print(f\"{'Train' if not self.validation else 'Valid'}:\\n\"\n",
    "              f\"\\tAverage loss: {self.running_loss[-1]:3.4f}\\n\"\n",
    "              f\"\\tMean error: {self.mean_err:3.3f}\\n\"\n",
    "              f\"\\tMean absolute error: {self.mean_abs_err:3.3f}\\n\"\n",
    "              f\"\\tError deviation: {self.std:3.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#HARD CODE\n",
    "\n",
    "@click.command()\n",
    "@click.option('-d', '--dataset_name',\n",
    "              type=click.Choice(['cell', 'mall', 'ucsd']),\n",
    "              required=True,\n",
    "              help='Dataset to train model on (expect proper HDF5 files).')\n",
    "@click.option('-n', '--network_architecture',\n",
    "              type=click.Choice(['UNet', 'FCRN_A']),\n",
    "              required=True,\n",
    "              help='Model to train.')\n",
    "@click.option('-lr', '--learning_rate', default=1e-2,\n",
    "              help='Initial learning rate (lr_scheduler is applied).')\n",
    "@click.option('-e', '--epochs', default=150, help='Number of training epochs.')\n",
    "@click.option('--batch_size', default=8,\n",
    "              help='Batch size for both training and validation dataloaders.')\n",
    "@click.option('-hf', '--horizontal_flip', default=0.0,\n",
    "              help='The probability of horizontal flip for training dataset.')\n",
    "@click.option('-vf', '--vertical_flip', default=0.0,\n",
    "              help='The probability of horizontal flip for validation dataset.')\n",
    "@click.option('--unet_filters', default=64,\n",
    "              help='Number of filters for U-Net convolutional layers.')\n",
    "@click.option('--convolutions', default=2,\n",
    "              help='Number of layers in a convolutional block.')\n",
    "@click.option('--plot', is_flag=True, help=\"Generate a live plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset_name: str,\n",
    "          network_architecture: str,\n",
    "          learning_rate: float,\n",
    "          epochs: int,\n",
    "          batch_size: int,\n",
    "          horizontal_flip: float,\n",
    "          vertical_flip: float,\n",
    "          unet_filters: int,\n",
    "          convolutions: int,\n",
    "          plot: bool):\n",
    "    \"\"\"Train chosen model on selected dataset.\"\"\"\n",
    "    # use GPU if avilable\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    dataset = {}     # training and validation HDF5-based datasets\n",
    "    dataloader = {}  # training and validation dataloaders\n",
    "\n",
    "    for mode in ['train', 'valid']:\n",
    "        # expected HDF5 files in dataset_name/(train | valid).h5\n",
    "        data_path = os.path.join(dataset_name, f\"{mode}.h5\")\n",
    "        # turn on flips only for training dataset\n",
    "        dataset[mode] = H5Dataset(data_path,\n",
    "                                  horizontal_flip if mode == 'train' else 0,\n",
    "                                  vertical_flip if mode == 'train' else 0)\n",
    "        dataloader[mode] = torch.utils.data.DataLoader(dataset[mode],\n",
    "                                                       batch_size=batch_size)\n",
    "\n",
    "    # only UCSD dataset provides greyscale images instead of RGB\n",
    "    input_channels = 1 if dataset_name == 'ucsd' else 3\n",
    "\n",
    "    # initialize a model based on chosen network_architecture\n",
    "    network = {\n",
    "        'UNet': UNet,\n",
    "        'FCRN_A': FCRN_A\n",
    "    }[network_architecture](input_filters=input_channels,\n",
    "                            filters=unet_filters,\n",
    "                            N=convolutions).to(device)\n",
    "    network = torch.nn.DataParallel(network)\n",
    "\n",
    "    # initialize loss, optimized and learning rate scheduler\n",
    "    loss = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(network.parameters(),\n",
    "                                lr=learning_rate,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=1e-5)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=20,\n",
    "                                                   gamma=0.1)\n",
    "\n",
    "    # if plot flag is on, create a live plot (to be updated by Looper)\n",
    "    if plot:\n",
    "        pyplot.ion()\n",
    "        fig, plots = pyplot.subplots(nrows=2, ncols=2)\n",
    "    else:\n",
    "        plots = [None] * 2\n",
    "\n",
    "    # create training and validation Loopers to handle a single epoch\n",
    "    train_looper = Looper(network, device, loss, optimizer,\n",
    "                          dataloader['train'], len(dataset['train']), plots[0])\n",
    "    valid_looper = Looper(network, device, loss, optimizer,\n",
    "                          dataloader['valid'], len(dataset['valid']), plots[1],\n",
    "                          validation=True)\n",
    "\n",
    "    # current best results (lowest mean absolute error on validation set)\n",
    "    current_best = np.infty\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\\n\")\n",
    "\n",
    "        # run training epoch and update learning rate\n",
    "        train_looper.run()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # run validation epoch\n",
    "        with torch.no_grad():\n",
    "            result = valid_looper.run()\n",
    "\n",
    "        # update checkpoint if new best is reached\n",
    "        if result < current_best:\n",
    "            current_best = result\n",
    "            torch.save(network.state_dict(),\n",
    "                       f'{dataset_name}_{network_architecture}.pth')\n",
    "\n",
    "            print(f\"\\nNew best result: {result}\")\n",
    "\n",
    "        print(\"\\n\", \"-\"*80, \"\\n\", sep='')\n",
    "\n",
    "    print(f\"[Training done] Best result: {current_best}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
